{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnning\n",
      "Done running\n",
      "Runnning\n",
      "Done running\n",
      "Runnning\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m   task\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# calls main\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(example_function())\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# momentarily pause to begin the await\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# resume function\u001b[39;00m\n\u001b[0;32m     18\u001b[0m task\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\asyncio\\tasks.py:639\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(delay, result)\u001b[0m\n\u001b[0;32m    635\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[0;32m    636\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[0;32m    637\u001b[0m                     future, result)\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done running\n",
      "Runnning\n",
      "Done running\n",
      "Runnning\n",
      "Done running\n",
      "Runnning\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def example_function():\n",
    "  while True: \n",
    "    # print item\n",
    "    print(f\"Runnning\")\n",
    "    # await sleep for one second\n",
    "    await asyncio.sleep(1)\n",
    "    # print the next statement\n",
    "    print(f\"Done running\")\n",
    "\n",
    "async def main():\n",
    "  # begin running task\n",
    "  task = asyncio.create_task(example_function())\n",
    "  # momentarily pause to begin the await\n",
    "  await asyncio.sleep(5)\n",
    "  # resume function\n",
    "  task.cancel()\n",
    "\n",
    "# calls main\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 32.07 seconds\n",
      "Agent 0: [2, 3, 5, 2, 5, 1, 3, 3, 2, 1, 5]\n",
      "Agent 1: [4, 5, 4, 5, 3, 2, 1, 3, 3]\n",
      "Agent 2: [1, 4, 4, 5, 1, 2, 2, 3, 4, 5]\n",
      "Agent 3: [5, 4, 3, 5, 4, 1, 2, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "global state \n",
    "\n",
    "class State():\n",
    "    def __init__(self):\n",
    "        self.state = {}\n",
    "        self.state_lock = asyncio.Lock() # Global Lock for safe state updates\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "\n",
    "    async def execute(self):\n",
    "        \"\"\"Simulate an agent performing a task.\"\"\"\n",
    "        randint = np.random.randint(1, 6)\n",
    "        factorial = 1\n",
    "        for i in range(1, randint + 1):\n",
    "            factorial *= i  # Simulating some computation\n",
    "\n",
    "        await asyncio.sleep(randint)  # Simulate API call or delay\n",
    "\n",
    "        return randint\n",
    "\n",
    "    async def agent_loop(self, id, ostate, start_time, time_limit):\n",
    "        \"\"\"Each agent runs its task repeatedly until the time limit is reached.\"\"\"\n",
    "        while time.time() - start_time < time_limit:\n",
    "            result = await self.execute()\n",
    "            async with ostate.state_lock:\n",
    "                if id not in ostate.state.keys():\n",
    "                    ostate.state[id] = []\n",
    "                ostate.state[id].append(result)\n",
    "            # print(f\"Agent {x} completed task with result: {result}\")\n",
    "\n",
    "async def main(agents, time_limit, state):\n",
    "    \"\"\"Start agent loops and run them asynchronously until the time limit.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a task for each agent that will keep running\n",
    "    tasks = [asyncio.create_task(x.agent_loop(x.id, state, start_time, time_limit)) for x in agents]\n",
    "    \n",
    "    # Wait for all tasks to stop when time limit is reached\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Define agents and time limit\n",
    "ostate = State()\n",
    "agents = [Agent(0), Agent(1), Agent(2), Agent(3)]\n",
    "time_limit = 30  # Run for 10 seconds\n",
    "\n",
    "start_time = time.time()\n",
    "await main(agents, time_limit, ostate)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")\n",
    "for agent, results in sorted(ostate.state.items()):\n",
    "    print(f\"Agent {agent}: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 15.55 seconds\n",
      "Agent 0: ['Warsaw, 0.6603217124938965', 'Tokyo, 1.162505865097046', 'Helsinki, 1.7051441669464111', 'Oslo, 2.2559573650360107', 'Berlin, 2.7698464393615723', 'Tokyo, 3.41169810295105', 'Tokyo, 3.929084300994873', 'Nairobi, 4.464965105056763', 'Bishkek, 4.995843410491943', 'Hanoi, 5.583045721054077', 'Helsinki, 6.350046634674072', 'Bucharest, 6.932950735092163', 'Tokyo, 7.481956958770752', 'Tokyo, 8.08025336265564', 'Hanoi, 8.719014406204224', 'Helsinki, 10.483686447143555', 'Vienna, 11.3879976272583', 'Tunis, 11.992833137512207', 'Oslo, 12.629380464553833', 'Bangkok, 13.21861982345581', 'Lisbon, 14.00692892074585', 'Tokyo, 14.612683057785034', 'Lisbon, 15.244638919830322']\n",
      "Agent 1: ['Nairobi, 0.5871882438659668', 'Lima, 1.189368724822998', 'Lisbon, 1.741905927658081', 'Bamako, 2.2960007190704346', 'Tokyo, 2.892963409423828', 'Helsinki, 3.432673215866089', 'Vienna, 4.433759927749634', 'Tunis, 4.987709045410156', 'Tallinn, 5.56728982925415', 'Hanoi, 6.205966472625732', 'Hanoi, 6.724200248718262', 'Lima, 7.289474248886108', 'Tokyo, 7.858356475830078', 'Tokyo, 8.40280795097351', 'Tokyo, 9.06728196144104', 'Nairobi, 9.64516806602478', 'Helsinki, 10.296654462814331', 'Buenos Aires, 10.862593650817871', 'Helsinki, 11.472357273101807', 'Malabo, 12.00195026397705', 'Nairobi, 12.650945663452148', 'Nairobi, 13.266239404678345', 'Hanoi, 13.873632192611694', 'Sucre, 14.52741026878357', 'Nairobi, 15.167524337768555']\n",
      "Agent 2: ['Nairobi, 0.7637166976928711', 'Banjul, 1.3476667404174805', 'Helsinki, 2.332868814468384', 'Bucharest, 2.9082067012786865', 'Helsinki, 3.47615647315979', 'Bangkok, 4.472746849060059', 'Tokyo, 5.171488523483276', 'Wellington, 5.706786394119263', 'Tokyo, 6.324840784072876', 'Helsinki, 6.916708707809448', 'Tokyo, 7.595423460006714', 'Lisbon, 8.231791734695435', 'Prague, 8.807427883148193', 'Tokyo, 9.690593719482422', 'Lisbon, 10.25382399559021', 'Wellington, 10.908666610717773', 'Tokyo, 11.459018468856812', 'Tokyo, 12.465998411178589', 'Lisbon, 13.057464122772217', 'Lisbon, 13.62414813041687', 'Lima, 14.2523934841156', 'Helsinki, 15.434038162231445']\n",
      "Agent 3: ['Lisbon, 0.5668070316314697', 'Lisbon, 1.1278159618377686', 'Lima, 1.7907071113586426', 'Tokyo, 2.666302442550659', 'Helsinki, 3.1738531589508057', 'Oslo, 3.7264318466186523', 'Lisbon, 4.3027403354644775', 'Lima, 5.595202684402466', 'Tokyo, 6.287834644317627', 'Nairobi, 6.880184650421143', 'Lisbon, 7.451471567153931', 'Berlin, 8.00360894203186', 'Hanoi, 8.570174217224121', 'Lisbon, 9.139381885528564', 'Helsinki, 9.693658113479614', 'Tokyo, 10.2790367603302', 'Oslo, 10.928898096084595', 'Lisbon, 11.624685049057007', 'Tokyo, 12.221160173416138', 'Helsinki, 12.855129718780518', 'Lisbon, 13.446281671524048', 'Canberra, 14.333187341690063', 'Tokyo, 15.19652795791626']\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Load in API Key and Handle Errors\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = AsyncOpenAI(api_key = openai_api_key)\n",
    "\n",
    "\n",
    "global state \n",
    "\n",
    "class State():\n",
    "    def __init__(self):\n",
    "        self.state = {}\n",
    "        self.state_lock = asyncio.Lock() # Global Lock for safe state updates\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.messages = []\n",
    "\n",
    "    async def execute(self):\n",
    "        # Query the LLM with full stack of current messages\n",
    "        completion = await client.chat.completions.create(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            messages = self.messages\n",
    "        )\n",
    "        return completion.choices[0].message # This returns only the AI's response in text without any \"context\". \n",
    "\n",
    "\n",
    "    async def agent_loop(self, ostate, start_time, time_limit):\n",
    "        \"\"\"Each agent runs its task repeatedly until the time limit is reached.\"\"\"\n",
    "        while time.time() - start_time < time_limit:\n",
    "            self.messages.append({'role':'system', 'content':'Return the name of a random capital city of the World'})\n",
    "            random_wait = .01 * np.random.randint(0, 5)\n",
    "            await asyncio.sleep(random_wait)\n",
    "            task = asyncio.create_task(self.execute())\n",
    "            result = await task\n",
    "            async with ostate.state_lock:\n",
    "                if self.id not in ostate.state.keys():\n",
    "                    ostate.state[self.id] = []\n",
    "                ostate.state[self.id].append(f\"{result.content}, {time.time() - start_time}\")\n",
    "            \n",
    "            await asyncio.sleep(0.1)\n",
    "            # print(f\"Agent {x} completed task with result: {result}\")\n",
    "\n",
    "async def main(agents, time_limit, state):\n",
    "    \"\"\"Start agent loops and run them asynchronously until the time limit.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a task for each agent that will keep running\n",
    "    tasks = [asyncio.create_task(x.agent_loop(state, start_time, time_limit)) for x in agents]\n",
    "    \n",
    "    # Wait for all tasks to stop when time limit is reached\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Define agents and time limit\n",
    "ostate = State()\n",
    "agents = [Agent(0), Agent(1), Agent(2), Agent(3)]\n",
    "time_limit = 15  # Run for 10 seconds\n",
    "\n",
    "start_time = time.time()\n",
    "await main(agents, time_limit, ostate)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")\n",
    "for agent, results in sorted(ostate.state.items()):\n",
    "    print(f\"Agent {agent}: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='I don’t have personal preferences, but I can help you find information about colors or discuss their meanings and associations! Do you have a favorite color?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n",
      "<class 'openai.types.chat.chat_completion_message.ChatCompletionMessage'>\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Load in API Key and Handle Errors\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = AsyncOpenAI(api_key = openai_api_key)\n",
    "\n",
    "\n",
    "global state \n",
    "\n",
    "class State():\n",
    "    def __init__(self):\n",
    "        self.state = {}\n",
    "        self.state_lock = asyncio.Lock() # Global Lock for safe state updates\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.messages = []\n",
    "\n",
    "    async def execute(self):\n",
    "        # Query the LLM with full stack of current messages\n",
    "        completion = await client.chat.completions.create(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            messages = self.messages\n",
    "        )\n",
    "        return completion.choices[0].message # This returns only the AI's response in text without any \"context\". \n",
    "\n",
    "\n",
    "    async def agent_loop(self, ostate, start_time, time_limit):\n",
    "        \"\"\"Each agent runs its task repeatedly until the time limit is reached.\"\"\"\n",
    "        while time.time() - start_time < time_limit:\n",
    "            self.messages.append({'role':'system', 'content':'Return the name of a random capital city of the World'})\n",
    "            random_wait = .01 * np.random.randint(0, 5)\n",
    "            await asyncio.sleep(random_wait)\n",
    "            task = asyncio.create_task(self.execute())\n",
    "            result = await task\n",
    "            async with ostate.state_lock:\n",
    "                if self.id not in ostate.state.keys():\n",
    "                    ostate.state[self.id] = []\n",
    "                ostate.state[self.id].append(f\"{result.content}, {time.time() - start_time}\")\n",
    "            \n",
    "            await asyncio.sleep(0.1)\n",
    "            # print(f\"Agent {x} completed task with result: {result}\")\n",
    "\n",
    "async def main(agents, time_limit, state):\n",
    "    \"\"\"Start agent loops and run them asynchronously until the time limit.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a task for each agent that will keep running\n",
    "    tasks = [asyncio.create_task(x.agent_loop(state, start_time, time_limit)) for x in agents]\n",
    "    \n",
    "    # Wait for all tasks to stop when time limit is reached\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Define agents and time limit\n",
    "ostate = State()\n",
    "agent = Agent(0)\n",
    "agent.messages.append({\"role\":\"user\", \"content\":\"What's your favorite color?\"})\n",
    "x = await agent.execute()\n",
    "print(x)\n",
    "print(type(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseModel.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchat_msg\u001b[39m():\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mchat_completion_message\u001b[38;5;241m.\u001b[39mChatCompletionMessage({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExample\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchat_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m, in \u001b[0;36mchat_msg\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchat_msg\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletionMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: BaseModel.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "def chat_msg():\n",
    "  return openai.types.chat.chat_completion_message.ChatCompletionMessage({'role':'user', 'content':'Example'})\n",
    "\n",
    "print(chat_msg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.types.chat.chat_completion_message.ChatCompletionMessage(content='No response received due to limit error. Please try again.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
