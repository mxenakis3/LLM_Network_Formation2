max_iters: 5
duration: 10
react_system_message: |
    You run in a loop of Thought, Action, Observation. 
    At the end of the loop you output an Answer. 
    Use Thought to describe your thoughts about the question you have been asked.
    Use Action to run one of the actions available to you.
    Observation will be the result of running those actions.

    Example session:

    Question: What is the mass of Earth times 2?
    Thought: I need to find the mass of Earth
    Action: get_planet_mass(Earth)

    You will be called again with this:

    Observation: 5.972e24

    Thought: I need to multiply this by 2
    Action: calculate(5.972e24 * 2)

    You will be called again with this: 

    Observation: 1,1944×10e25

    If you have the answer, output it as the Answer.

    Answer: The mass of Earth times 2 is 1,1944×10e25.
game_rules: |
    You are in a multiplayer game where the object is to earn the highest payoff. 

    In this game, each player controls the color (either 0 or 1) of a vertex in a network.

    If the entire network picks color 0, your maximum projected payoff will be {consensus_0_reward}.
    If the entire network picks color 1, your maximum projected payoff will be {consensus_1_reward}.
    If no consensus is reached, you will not win any money.

    You will have two pieces of information about the network, for all players of the game, at all times, given as two dictionaries (to follow):
    1. Degree: The number of connections each player has to other players.
    2. Shortest path distance (spls): Your minimum degree of separation from every other player in the game.

    You are only able to see the colors of a subset of players to whom you are already connected in the network via an edge. 
    Each key in this dictionary, called "colors" represents the ID of another agent with whom you are already connected. Each value represents their color.
    If the agent has not committed to a color, their color will appear as "Undeclared".

    Edges (or, connections) to players to whom you are not connected (any player that does NOT already appear in your colors dictionary, to follow)
    can be purchased at a price of {edge_cost}, which will be deducted from your projected payoff. You will not have to pay for any edges if the network fails to come to a consensus. 

    When you buy an edge to another player, the state of the network refreshes. On your next turn, both you and the other player will be able to see each other's colors. 

    Once an edge has bought, it will remain in the network until the game expires. 

    There are {total_iters} iterations or turns in this game, and you have {iters_remaining} turns remaining. 
agent_options: |
    Note again that if the colors of your connections is an empty dictionary, it is because you do not have any existing connections. 
    You may purchase connections to any players that are in the degree/ shortest path dictionaries but are not in your colors dictionary. 
    
    The color of your new connection will be visible to you after the colors dictionary refreshes at the beginning of your next turn. 
    
    It is your turn to decide how to play the game.

    Your available actions are:
      1. game_question({question as string}): 
        Send a query to an administrator regarding the rules of the game. The input should be the question that you have, formatted as a string. 
      2. check_time():
        Check the number of iterations remaining in the simulation
      3. purchase_edge(neighbor_id):
        purchase an edge to a neighbor 
      4. set_color({color}):
        set your color to either zero or 1
      5. finish():
        complete loop
react_max_iters: 10
init_configs:
  duration: 60 # time of experiment in seconds
  V: 4
  agent_0:
    consensus_0_reward: 3
    consensus_1_reward: 2
    edge_cost: 0.03
  agent_1:
    consensus_0_reward: 2
    consensus_1_reward: 3
    edge_cost: 0.03
  